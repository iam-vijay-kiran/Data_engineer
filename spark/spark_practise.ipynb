{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b85efbf-7d21-4736-9978-c52f4fc2dcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# initialize the spark session\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"pyspark practise\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Reading the csv files\n",
    "employees = spark.read.csv('path_of_the_file/file_name',inferSchema=True,header=True)\n",
    "departments = spark.read.csv('departments.csv',inferSchema=True,header=True)\n",
    "regions = spark.read.csv('regions',inferSchema=True,header=True)\n",
    "\n",
    "#Narrow Transformation\n",
    "filtered_employees = employees.filter(employees.age>30)\n",
    "\n",
    "#Wide Transformation \n",
    "result = filtered_employees.join(department,filtered_employees.dept_id==departments.dept_id)\n",
    "\n",
    "# another wide transformations\n",
    "result_with_region = result.join(regions,result.region_id=region.region_id)\n",
    "\n",
    "# action:collect\n",
    "result_list = result_with_region.collect()\n",
    "\n",
    "# narrow transformation\n",
    "selected_data = result_with_region.select('employee_name','department_name','region_name')\n",
    "\n",
    "#action\n",
    "selected_data.write.csv(result.csv)\n",
    "\n",
    "#stop spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4323d5ee-d45b-4612-b0a6-66c54b1a118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spark.sql import SparkSesion\n",
    "\n",
    "# initialize spark session\n",
    "spark = SparkSession.builder\\\n",
    "        .appName('practise')\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# reading the file\n",
    "csv1 = spark.read.csv('csv1.csv',inferSchema='True',header='True')\n",
    "csv2 = spark.read.csv('csv2.csv',inferSchema='True',header='True')\n",
    "csv3 = spark.read.csv('csv3.csv',inferSchema='True',header='True')\n",
    "\n",
    "# narrow transformation\n",
    "filter_emp = csv.filter(csv1.age>30)\n",
    "\n",
    "# wide transformation\n",
    "result = filter_emp.join(csv2, filter_map.dept_id=csv2.dept_id)\n",
    "\n",
    "# wide trans\n",
    "result1 = filter_emp.join(csv3,result.region_id=csv3.region_id)\n",
    "\n",
    "# action collect\n",
    "result_list = result1.collect()\n",
    "\n",
    "# narrow trans\n",
    "selected_data = result1.select('employee_name','department_name','region_name')\n",
    "\n",
    "# action save to csv\n",
    "selected_data.write.csv(result.csv)\n",
    "\n",
    "#stop spark\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
